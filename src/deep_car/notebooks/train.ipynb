{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "This notebook train a neural network. It dependes on the `train.hdf5` and `test.hdf5` files. So make sure you run the `rosbag_to_hdf5.ipynb` notebook first. \n",
    "\n",
    "## Network architecture\n",
    "\n",
    "We use a convolutional neural network. The input is of size `(60, 80)`. We use a building block of 5x5 convolutional layer with padding, batch normalization, relu activation and then a max pooling layer. This is repeated until the feature maps reach size `(6, 8)`. For more details see the code in the `model.py` code module.\n",
    "\n",
    "## Data augmentation\n",
    "\n",
    "The images are augmented by random crops, brightness adapation and contrast changes. For details the the `data.py` module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import six\n",
    "from six.moves import range\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageOps\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.font_manager\n",
    "from PIL import ImageDraw, ImageFont, ImageFilter\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "from deep_car.data import augment_img, augment_batch, crop_batch\n",
    "from deep_car.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "model_dir = '../data/model'\n",
    "model_name = 'steering_mixture_prob_exp'\n",
    "tmp_dir = '../tmp'\n",
    "\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "crop_size = (64, 48)\n",
    "\n",
    "h5_train = h5py.File(os.path.join(data_dir, 'train.hdf5'))\n",
    "h5_test = h5py.File(os.path.join(data_dir, 'test.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:25}| {:10}| {:30}\".format(\"name\", \"dtype\", \"shape\"))\n",
    "print(\"-\" * 40)\n",
    "for name, dset in h5_train.items():\n",
    "    print(\"{:25}| {:10}| {:30}\".format(name, str(dset.dtype), str(dset.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(h5, batch_size=128, n_epoch=-1, shuffle=True, steering_distance_max=500):\n",
    "    def get_steering(idx):\n",
    "        idx = clip(idx)\n",
    "        return np.array(steering[idx])\n",
    "\n",
    "    def clip(x):\n",
    "        return np.clip(x, 0, n-1)\n",
    "\n",
    "    steering = np.array(h5['steering'])\n",
    "\n",
    "    n = len(h5['image'])\n",
    "    idx = np.arange(n)\n",
    "    if n_epoch == -1:\n",
    "        n_epoch = 1000000000\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        if shuffle:\n",
    "            np.random.shuffle(idx)\n",
    "        for b in range(0, n, batch_size):\n",
    "            batch_idx = np.sort(idx[b:b+batch_size])            \n",
    "            batch = {\n",
    "                'image': h5['image'][batch_idx, :, :],\n",
    "                'steering_abs': h5['steering'][batch_idx, :],\n",
    "            }\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(data_generator(h5_train))\n",
    "for name, arr in sorted(batch.items()):\n",
    "    print(\"{:<17} | {:} \".format(name, arr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['image'].min(), batch['image'].max(), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark the data iterator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1\n",
    "\n",
    "for batch in data_generator(h5_test, n_epoch=1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Display the augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(data_generator(h5_train))\n",
    "images = [PIL.Image.fromarray(x) for x in batch[\"image\"]]\n",
    "img = images[0]\n",
    "fig, axes = plt.subplots(4, 12, figsize=(20, 5))\n",
    "\n",
    "fig.suptitle(\"First row: Images from the dataset, Second row: Augmented images\", fontsize=20)\n",
    "\n",
    "images =  images[:len(axes[:1][0])]\n",
    "for ax, img in zip(axes[:1].flat, images):\n",
    "    ax.imshow(np.array(img), cmap='gray', vmin=0, vmax=255)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for ax, img in zip(axes[1:].flat, itertools.cycle(images)):\n",
    "    ax.imshow(np.array(augment_img(img)), cmap='gray', vmin=0, vmax=255)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_to_numpy(batch):     \n",
    "    x = 2. * batch['image'] / 255. - 1                                          \n",
    "    steering_abs = batch['steering_abs']                                                                              \n",
    "    return x[:, :, :, np.newaxis], steering_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_aug = augment_batch(batch)\n",
    "x_image, x_steering_abs = batch_to_numpy(batch_aug)\n",
    "\n",
    "for name, arr in [\n",
    "    ('data', x_image),\n",
    "    ('steering_abs', x_steering_abs),\n",
    "]:\n",
    "    print(\"{:30} | {:20} | {:10} | {:10}\".format(name, str(arr.shape), float(arr.min()), float(arr.max())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "input_shape = [None, crop_size[1], crop_size[0], 1]\n",
    "m = Model(input_shape)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = {}\n",
    "for name in ['steering_abs']:\n",
    "    history[name] = []\n",
    "    history[\"val_\" + name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches_per_epoch = len(h5_train['image']) // batch_size\n",
    "\n",
    "tqdm_gen = tqdm(data_generator(h5_train, batch_size=batch_size, n_epoch=20))\n",
    "running_loss = 'init'\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "now = datetime.now()\n",
    "save_dir = os.path.join(model_dir, model_name + \"_\" + now.isoformat())\n",
    "os.makedirs(save_dir)\n",
    "\n",
    "for i, batch in enumerate(tqdm_gen):\n",
    "    x_image, x_steering_abs = batch_to_numpy(augment_batch(batch))\n",
    "    steering_loss, _ = sess.run(\n",
    "        [m.steering_abs_loss, m.opt_op], \n",
    "        feed_dict={\n",
    "            m.image: x_image, \n",
    "            m.steering_abs_true: x_steering_abs,\n",
    "            m.training: True,\n",
    "    })\n",
    "    \n",
    "    history['steering_abs'].append(np.mean(steering_loss))\n",
    "    batch_loss = np.mean(steering_loss)\n",
    "    if running_loss == 'init':\n",
    "        running_loss = batch_loss\n",
    "    else:\n",
    "        running_loss = 0.9*running_loss + 0.1*batch_loss\n",
    "        \n",
    "    if i % n_batches_per_epoch == 0:\n",
    "        val_steering_abs = []\n",
    "        for test_batch in data_generator(h5_test, batch_size=batch_size, n_epoch=1):\n",
    "            x_image, x_steering_abs = batch_to_numpy(crop_batch(test_batch))\n",
    "            steering_abs_loss = sess.run(\n",
    "                [m.steering_abs_loss],\n",
    "                feed_dict={\n",
    "                    m.image: x_image, \n",
    "                    m.steering_abs_true: x_steering_abs,\n",
    "                }\n",
    "            )\n",
    "            val_steering_abs.append(np.mean(steering_abs_loss))\n",
    "            \n",
    "        history['val_steering_abs'].append(np.mean(val_steering_abs))\n",
    "            \n",
    "    tqdm_gen.set_description('loss: {:.02f} - val_loss: {:.02f}'.format(running_loss, history['val_steering_abs'][-1]))\n",
    "\n",
    "save_path = saver.save(sess, os.path.join(save_dir, model_name + \".ckpt\"))\n",
    "print(\"Saved model in: \" + os.path.abspath(save_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
