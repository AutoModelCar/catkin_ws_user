{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converts recorded rosbags to hdf5 file\n",
    "\n",
    "The data is recorded with the `rosbag` command. To train a neural network, it is more convienient to have\n",
    "the data in the hdf5 file format. This notebook converts the data.\n",
    "\n",
    "## Train and Test Split\n",
    "\n",
    "Each rosbag is assigned either to the train or the test data. This is defined in the\n",
    "`train.txt` and `test.txt` files. \n",
    "\n",
    "## Important Parameters\n",
    "\n",
    "* `data_dir`: Writes data to this directory\n",
    "* `rosbag_fname`: Filename of a rosbag file of which a video with steering and speed is created.\n",
    "* `mode`: Must be either `train` or `test`. \n",
    "\n",
    "## Important: You have to run this notebook twice!\n",
    "\n",
    "First with `mode = \"train\"` and then with `mode = \"test\"` to generate\n",
    "both train and test hdf5 files. You may skip the video generation for the second run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import rosbag\n",
    "import rospy\n",
    "import numpy as np\n",
    "from sensor_msgs.msg import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from scipy.misc import imsave, imread\n",
    "import os\n",
    "from StringIO import StringIO\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import PIL\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager\n",
    "\n",
    "from PIL import ImageDraw, ImageFont, ImageFilter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import h5py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "data_dir = '../data'\n",
    "video_dir = os.path.join(data_dir, \"video\")\n",
    "rosbag_dir = os.path.join(data_dir, 'rosbag')\n",
    "\n",
    "# either train or test\n",
    "mode = 'test'\n",
    "\n",
    "rosbag_fname = os.path.join(rosbag_dir, '2017-05-31-14-20-54.bag')\n",
    "rosbag_name, _ = os.path.splitext(os.path.basename(rosbag_fname))\n",
    "\n",
    "def get_filenames(txt_file):\n",
    "    return [l.rstrip('\\n') for l in f.readlines()]\n",
    "    \n",
    "    \n",
    "with open(os.path.join(rosbag_dir, \"train.txt\"), 'r') as f: \n",
    "    train_rosbags = get_filenames(f)\n",
    "    \n",
    "with open(os.path.join(rosbag_dir, \"test.txt\"), 'r') as f: \n",
    "    test_rosbags = get_filenames(f)\n",
    "    \n",
    "print(\"TRAIN\", train_rosbags)\n",
    "print(\"TEST\", test_rosbags)\n",
    "\n",
    "if mode == 'train':\n",
    "    rosbag_fnames_to_convert = train_rosbags\n",
    "elif mode == 'test':\n",
    "    rosbag_fnames_to_convert = test_rosbags\n",
    "else:\n",
    "    raise Exception()\n",
    "    \n",
    "rosbag_fnames_to_convert = [os.path.join(rosbag_dir, f) for f in rosbag_fnames_to_convert]\n",
    "\n",
    "rescale_factor = 8\n",
    "tmp = os.path.abspath('../tmp/')\n",
    "if not os.path.exists(tmp):\n",
    "    os.makedirs(tmp)\n",
    "    \n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "    \n",
    "if not os.path.exists(video_dir):\n",
    "    os.makedirs(video_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class topics:\n",
    "    image_raw = \"/app/camera/rgb/image_raw/compressed\"\n",
    "    image_resize = \"/deepcar/resize_img80x60/compressed\"\n",
    "    lights = \"/manual_control/lights\"\n",
    "    speed = \"/manual_control/speed\"\n",
    "    steering = \"/manual_control/steering\"\n",
    "    stop_start = \"/manual_control/stop_start\"\n",
    "    yaw = \"/model_car/yaw\"\n",
    "    twist = \"/motor_control/twist\" \n",
    "    odom = \"/odom\"\n",
    "    \n",
    "    labels = [speed, steering, yaw]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ros_to_numpy(msg):\n",
    "    return imread(StringIO(msg.data))\n",
    "\n",
    "def ros_to_pil(msg):\n",
    "    return PIL.Image.open(StringIO(msg.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = rosbag.Bag(rosbag_fname)\n",
    "bag.get_start_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(t):\n",
    "    return (1-t)*bag.get_start_time() + t*bag.get_end_time()\n",
    "\n",
    "print(bag.get_start_time())\n",
    "print(get_time(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tti = bag.get_type_and_topic_info()\n",
    "\n",
    "fmt = \"{:40}| {:30}| {:<20}\"\n",
    "print(fmt.format(\"topic\", \"message type\", \"count\"))\n",
    "print(\"-\" * 80)\n",
    "for name, topic in sorted(tti.topics.items()):\n",
    "    print fmt.format(name, topic.msg_type, topic.message_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_topic(bag):\n",
    "    tti = bag.get_type_and_topic_info()\n",
    "\n",
    "    if topics.image_raw in tti.topics.keys():\n",
    "        return topics.image_raw\n",
    "    \n",
    "    assert topics.image_resize in  tti.topics.keys()\n",
    "    return topics.image_resize \n",
    "\n",
    "image_topic = get_image_topic(bag)\n",
    "image_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all messages for lables and convert them to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_msg(msg, msg_type):\n",
    "    if msg_type in (\"std_msgs/Int16\", \"std_msgs/Float32\"):\n",
    "        return msg.data\n",
    "    elif msg_type == 'geometry_msgs/Twist':\n",
    "        return {\n",
    "            msg.linear.x,\n",
    "        }\n",
    "    else:\n",
    "        raise Exception('unknown')\n",
    "    \n",
    "def get_labels_as_pandas(bag, topics=topics.labels):\n",
    "    topic_data = {t: [] for t in topics}\n",
    "    times = {t: [] for t in topics}\n",
    "    for topic, msg, time in bag.read_messages(topics=topics):\n",
    "        msg_type = tti.topics[topic].msg_type\n",
    "        data = parse_msg(msg, msg_type)\n",
    "        times[topic].append(time.to_sec())\n",
    "        topic_data[topic].append(data)\n",
    "    df = {}\n",
    "    for k, data in topic_data.items():\n",
    "        df[k] = pd.Series(data, index=pd.DatetimeIndex(pd.to_datetime(times[k], unit='s')))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_bags = train_rosbags + test_rosbags\n",
    "fig, axes = plt.subplots(ncols=len(all_bags), figsize=(25, 7))\n",
    "for ax, bag_fname in zip(axes, sorted(all_bags)):\n",
    "    bag = rosbag.Bag(os.path.join(rosbag_dir, bag_fname))\n",
    "    df = get_labels_as_pandas(bag, ['/manual_control/steering'])\n",
    "    steering = df['/manual_control/steering']\n",
    "    steering.hist(ax=ax)\n",
    "    ax.set_title(bag_fname)\n",
    "    \n",
    "plt.show(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = rosbag.Bag(rosbag_fname)\n",
    "print(rosbag_fname)\n",
    "df = get_labels_as_pandas(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = tti.topics[image_topic].frequency\n",
    "print(\"Frame rate is: {:.2f}\".format(frame_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def command_at(df, time):\n",
    "    if type(time) == rospy.rostime.Time:\n",
    "        time = time.to_sec()\n",
    "    dt = pd.to_datetime(time, unit='s')\n",
    "    before = df[:dt]\n",
    "    if len(before) != 0:\n",
    "        return before[-1]\n",
    "    else:\n",
    "        return df[dt:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a video with steering, speed, and time [optional]\n",
    "\n",
    "Visualizes the steering, speed and time in a video. This is completly optional and may be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def image_draw_info(img, speed, steering, time, font=None):\n",
    "    if font is None:\n",
    "        fonts = matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "        mono_fonts = [f for f in fonts if \"mono\" in f.lower() and 'bold' in f.lower()]\n",
    "        mono_font = mono_fonts[0]\n",
    "        font = ImageFont.truetype(mono_font, 18)\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    draw.text((10, 450), time, fill=\"#ffffff\", font=font)\n",
    "    draw.text((10, 20), \"steering: {}\".format(steering), fill=\"#00ff00\", font=font)\n",
    "    angle = (steering) / 180. * np.pi\n",
    "    x = img.size[0] / 2\n",
    "    y = 100\n",
    "    draw.line([x, y, x +  60*np.cos(angle), y  - 60*np.sin(angle)], fill=\"#00ff00\", width=3)\n",
    "    draw.text((10, 50), \"speed: {}\".format(speed), fill='#ff0000', font=font)\n",
    "    del draw\n",
    "\n",
    "    \n",
    "img_fnames = []\n",
    "tmp_dir = tempfile.mkdtemp(dir=tmp)\n",
    "\n",
    "for i, (topic, msg, time) in enumerate(tqdm(\n",
    "    bag.read_messages(topics=image_topic, end_time=rospy.Time(get_time(0.5))))):\n",
    "    \n",
    "    img_fname = os.path.join(tmp_dir, \"{:06d}.png\".format(i))\n",
    "    img = ros_to_numpy(msg)\n",
    "    \n",
    "    img = PIL.Image.fromarray(img)\n",
    "    for name, d in df.items():\n",
    "        value = command_at(d, time)\n",
    "        \n",
    "        if name == topics.steering:\n",
    "            steering = value\n",
    "        elif name == topics.speed:\n",
    "            speed = value\n",
    "    dtime = datetime.fromtimestamp(time.to_sec())\n",
    "    image_draw_info(img, speed, steering, dtime.isoformat())\n",
    "    img.save(img_fname)\n",
    "    del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video = ImageSequenceClip(tmp_dir, fps=frame_rate, with_mask=False)\n",
    "output_fname = os.path.abspath(os.path.join(video_dir, rosbag_name + \"_controls.webm\"))\n",
    "video.write_videofile(output_fname, ffmpeg_params=['-b:v', '0', '-crf', '20'])\n",
    "shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hdf5 file and convert all rosbag files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_img(img):\n",
    "    blur = ImageFilter.GaussianBlur(radius=rescale_factor * 1./3)\n",
    "    return img.convert('L').filter(blur).resize(img_shape_pil, resample=PIL.Image.BILINEAR)\n",
    "\n",
    "# numpy it is h, w and in the PIL world w, h\n",
    "img_shape_pil = (80, 60)\n",
    "img_shape = (60, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_fname = os.path.join(data_dir, mode + '.hdf5')\n",
    "if os.path.exists(h5_fname):\n",
    "    os.remove(h5_fname)\n",
    "h5 = h5py.File(h5_fname)\n",
    "print(\"saving h5 file to: \" + h5_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 32\n",
    "h5.create_dataset('image', shape=(1, ) + img_shape, dtype='uint8',\n",
    "                  maxshape=(None,) + img_shape,\n",
    "                  chunks=(64,) + img_shape)\n",
    "\n",
    "h5.create_dataset('steering', shape=(1, 1), dtype='float32', maxshape=(None, 1), chunks=(chunk, 1))\n",
    "h5.create_dataset('timestamp', shape=(1, 1), dtype='float64', maxshape=(None, 1), chunks=(chunk, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steering_norm = np.array([1 / 180. * np.pi, -np.pi/2])\n",
    "h5['steering'].attrs['normalize'] = steering_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(normalize, value):\n",
    "    return np.dot(normalize, [value, 1])\n",
    "\n",
    "i = 0\n",
    "print(\"Filling h5 file {} with data from {}\".format(h5_fname, rosbag_fnames_to_convert))\n",
    "for fname in rosbag_fnames_to_convert:\n",
    "    bag = rosbag.Bag(fname)\n",
    "    image_topic = get_image_topic(bag)\n",
    "    dfs = get_labels_as_pandas(bag, ['/manual_control/steering'])\n",
    "    steering_df = dfs['/manual_control/steering']\n",
    "    for topic, msg, time in tqdm(bag.read_messages(topics=image_topic)):\n",
    "        for dset in h5.values():\n",
    "            dset.resize(size=i+1, axis=0)\n",
    "        \n",
    "        img = ros_to_pil(msg)\n",
    "        if image_topic == topics.image_raw:\n",
    "            h5['image'][i] = np.array(rescale_img(img))\n",
    "            h5['steering'][i] = normalize(steering_norm, command_at(steering_df, time))\n",
    "        elif image_topic == topics.image_resize:\n",
    "            h5['image'][i] = np.array(img.convert('L'))\n",
    "            steering = command_at(steering_df, time)\n",
    "            h5['steering'][i] = normalize(steering_norm, 180 - steering)\n",
    "        else:\n",
    "            raise Exception()\n",
    "        h5['timestamp'][i] = time.to_sec()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:20}| {:10}| {:30}\".format(\"name\", \"dtype\", \"shape\"))\n",
    "print(\"-\" * 40)\n",
    "for name, dset in h5.items():\n",
    "    print(\"{:20}| {:10}| {:30}\".format(name, dset.dtype, dset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 100\n",
    "images = [h5['image'][i*step] for i in range(10)]\n",
    "PIL.Image.fromarray(np.concatenate(images, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
